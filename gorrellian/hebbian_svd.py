"""
Incremental PCA, SVD using Hebbian updates (from data only).

  PCA problem:
  Given many data vectors x, find the eigenvectors of the correlation matrix R,
  where E(xx') = R.

  SVD problem:
  Given many data vector pairs (a,b), where a=Mb, find the singular vectors of M.

  References:

  Zhang, “Complex-Valued Neural Networks“, 2003.
    https://www.mbari.org/wp-content/uploads/2016/01/Zhang_bookchapter_2003.pdf

  G. Gorrell, “Generalized Hebbian algorithm for incremental singular value
  decomposition in natural language processing,” EACL 2006, 11st Conference of
  the European Chapter of the Association for Computational Linguistics,
  Proceedings of the Conference, April 3-7, 2006, Trento, Italy (D. McCarthy
  and S. Wintner, eds.), The Association for Computer Linguistics, 2006.

"""

import os
import jax

if os.uname()[1] != 'sol':
    jax.config.update("jax_enable_x64", True)

from jax import jit
from jax.numpy import array, outer, eye, zeros, tril, triu, sqrt, isnan
from jax.numpy.linalg import svd, eig, inv, norm


@jit
def couter(a, b):
    """
    Complex outer product of a and b: a x b^T.
    """
    return outer(a, b.conjugate())


# TODO: rewrite and test PCA functions
def pca_update(W, x, eta=1e-3):
    """
    Incremental update to approximate eigenvector matrix W of correlation matrix R
      with one data vector x. Returns updated W.
    See Zhang's book and the Wikipedia page on GHA.
    """
    y = conj(W.T) @ x
    return W + eta * ((couter(x, x) @ W) - (W @ triu(couter(y, y))))


def pca_solve(gen_vector, iterations=100000, verbose=False):
    """
    Solve iteratively for the eigenvectors of the correlation matrix.
    Exponential decay d on learning rate eta.
    """
    v = gen_vector()
    W = eye(len(v))
    for n in range(iterations):
        v = gen_vector()
        if verbose and n % 1000 == 0:
            print(f"{n:07d}, {W[..., 1]}    ", end='\r')
        W = pca_update(W, v, eta=eta_decayed)
    return W


def pca_test(A, **kwargs):
    R = A @ conj(A.T)
    L_ref, W_ref = eig(R)
    W0 = eye(R.shape[0])
    W = pca_solve(rng.standard_normal([N, N]), **kwargs)
    L = (inv(W) @ R @ W).diagonal()
    print("A")
    print(A)
    print()
    print("R")
    print(R)
    print()
    print("W (ref)")
    print(W_ref)
    print()
    print("W (GHA)")
    print(W)
    print()
    print("R W (ref)")
    print(R @ W_ref)
    print()
    print("R W (GHA)")
    print(R @ W)
    print()
    print("L (ref)")
    print(L_ref)
    print()
    print("L (GHA)")
    print(L)
    print()


@jit
def dXdt(U, V, a, b):
    ya = U.T.conjugate() @ a
    yb = V.T.conjugate() @ b
    return couter(a, yb) - (U @ triu(couter(ya, yb))), \
            couter(b, ya) - (V @ triu(couter(yb, ya)))


@jit
def svd_update(U, V, a, b, eta=1e-4):
    """
    Incremental update to approximate SVD matrices U, V of operator A
      with one data vector pair a, b. Returns updated U, V.
    See Gorrell's paper.
    """
    ya = U.T.conjugate() @ a
    yb = V.T.conjugate() @ b
    return {
        "U": (U + (eta * (couter(a, yb) - (U @ triu(couter(ya, yb)))))),
        "V": (V + (eta * (couter(b, ya) - (V @ triu(couter(yb, ya)))))),
    }


# better to use an implicit method like CN for stability
# not sure RK4 is worth the expense here
@jit
def svd_update_rk4(U, V, a, b, eta=1e-4):
    """
    Incremental update to approximate SVD matrices U, V of operator A
      with one data vector pair a, b. Returns updated U, V.
    See Gorrell's paper.
    Use RK4 instead of Euler in 'solver stepsize time'.
    """
    """
      k_1	        = h f( v(n),        )
      k_2	        = h f( v(n) + k_1/2 )
      k_3	        = h f( v(n) + k_2/2 )
      k_4	        = h f( v(n) + k_3   )
      v(n+1) - v(n) = + k_1/6 + k_2/3 + k_3/3 + k_4/6 + O(h^5)	
    """
    Uk1, Vk1 = dXdt(U,               V,               a, b)
    Uk2, Vk2 = dXdt(U + eta * Uk1/2, V + eta * Vk1/2, a, b)
    Uk3, Vk3 = dXdt(U + eta * Uk2/2, V + eta * Vk2/2, a, b)
    Uk4, Vk4 = dXdt(U + eta * Uk3,   V + eta * Vk3,   a, b)
    return {
        "U": U + eta * (Uk1/6 + Uk2/3 + Uk3/3 + Uk4/6),
        "V": V + eta * (Vk1/6 + Vk2/3 + Vk3/3 + Vk4/6)
    }


def svd_solve(gen_pair, L=5, eta=1e-3, C_barrier=0.1, verbose=False):
    """
    Solve iteravely for the first L singular vectors of A,
    where gen_pair is a function that returns data pairs generated by A:
        a, b, key = gen_pair(key)

    Keep going until basis seems to have converged.
    """
    key = jax.random.PRNGKey(10)
    a, b, key = gen_pair(key)
    N = len(a)
    M = len(b)
    # initial guess for basis U, V
    U = eye(N, L) * eta
    V = eye(M, L) * eta
    U0, V0 = U, V
    if verbose:
        print(f"eta: {eta}, N: {N}, M: {M}")
    C_last = 100 * max(N, M)
    C = 10 * max(N, M)
    iter = 0
    while C_last > C or C > C_barrier:
        # best guess for number of iterations required
        iterations = int(1 / eta)
        for n in range(1000):
            a, b, key = gen_pair(key)
            UV = svd_update_rk4(U, V, a, b, eta=eta)
            U = UV['U']
            V = UV['V']
            iter += 1
            eta = eta * (1 - eta)
        if isnan(UV['U']).any() or isnan(UV['V']).any():
            U, V = U0, V0
            eta = eta / 2
            print(f"eta too large, reducing to {eta:0.3e}.  ")
        else:
            U0, V0 = U, V
        if verbose:
            # U'U and V'V should approach I with convergence; print the diagonals.
            print(f"  {iter/iterations:.0%} {iter:07d}/{iterations:07d}  C: {C:05f}  eta: {eta:0.2e}    ", end='\r')
        # rough convergence criterion based on approach to unitary U, V
        C_last = C
        C = norm(U.conjugate().T @ U - eye(L)) + norm(V.conjugate().T @ V - eye(L))
    return {"U": U, "V": V}


def svd_test(A, gen_pair, **kwargs):
    with jax.numpy.printoptions(precision=2):
        UV = svd_solve(gen_pair, **kwargs)
        with open('../data/U.npy', 'wb') as f:
            jax.numpy.save(f, U)
        with open('../data/V.npy', 'wb') as f:
            jax.numpy.save(f, V)
        print("saved result.")
        U = UV["U"]
        V = UV["V"]
        S = U.T.conjugate() @ A @ V
        print()
        print("U'U (GHA)")
        print(U.conjugate().T @ U)
        print()
        print("V'V (GHA)")
        print(V.conjugate().T @ V)
        print()
        print("S (GHA)")
        print(array(list(reversed(sorted(S.diagonal().real)))))
        print()
        return UV
        #print("S (true)")
        #print(svd(A, compute_uv=False)[0:L])
        #print()

